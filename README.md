# ğŸ¤– LocalAgent v1.0

**Your AI. Your machine. Your rules.**

A complete, privacy-first AI agent platform that runs entirely on your machine via Ollama. Zero cloud calls. Full autonomy. Forever yours.

---

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.10+**
- **Node.js 18+** & npm
- **Ollama** (for local LLM)

### One-Command Setup

```bash
chmod +x install.sh
./install.sh
```

This will:
1. âœ… Check all dependencies
2. âœ… Pull llama3.2 model via Ollama
3. âœ… Install backend Python packages
4. âœ… Install frontend npm dependencies
5. âœ… Start both services automatically
6. âœ… Open browser to http://localhost:3002

---

## ğŸ“‹ Architecture

### Backend (FastAPI)
- **48 REST API endpoints**
- **File-based persistence** (JSON/JSONL in `/backend/data/`)
- **Cross-session memory** system for continuous learning
- **Intelligent context builder** with smart message compression
- **Ollama integration** for local LLM (OpenAI-compatible API)
- **Optional integrations:**
  - ElevenLabs (text-to-speech, multilingual)
  - Twilio (voice calling)

### Frontend (Next.js 15 + React 19)
- **Interactive 3D grid** landing page (Three.js + OrbitControls)
- **âŒ˜K Command Palette** for action search
- **Minimizable chat overlay** with voice I/O
- **Real-time dashboards** for sessions, messages, prompts
- **Glassmorphic UI** with dark mode
- **Tailwind CSS** styling

### Key Features
- ğŸ” **100% Local** - No cloud required
- ğŸ® **Interactive 3D Experience** - Spin the grid while chatting
- ğŸ§  **9 Prompt Types** - Task, Learn, Roles, Schedule, Time Target, Debate, Interview, Forbidden Words, Read
- ğŸ“Š **Session Management** - Archive/restore conversations
- ğŸ”Š **Voice I/O** - Speech recognition + text-to-speech (optional)
- ğŸ’¾ **Persistent Memory** - Cross-session learning

---

## ğŸ“¦ Directory Structure

```
LocalAgent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI server (48 endpoints)
â”‚   â”œâ”€â”€ prompt_system.py        # Prompt types & session management
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ .env.template          # Configuration template
â”‚   â”œâ”€â”€ data/                  # File-based storage
â”‚   â”‚   â”œâ”€â”€ sessions/          # Conversation archives
â”‚   â”‚   â”œâ”€â”€ recordings/        # Voice recordings
â”‚   â”‚   â””â”€â”€ memory.jsonl       # Cross-session memory
â”‚   â””â”€â”€ venv/                  # Python virtual environment
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx           # Landing page (3D interactive grid)
â”‚   â”‚   â””â”€â”€ app/               # Main application hub
â”‚   â”‚       â”œâ”€â”€ page.tsx       # Dashboard with âŒ˜K menu
â”‚   â”‚       â””â”€â”€ [view]/        # Sub-pages (sessions, prompts, etc.)
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Interactive3DGrid.tsx      # Full interactive 3D scene
â”‚   â”‚   â”œâ”€â”€ Interactive3DGridBg.tsx    # Subtle blurred background
â”‚   â”‚   â”œâ”€â”€ ActionSearchBar.tsx        # âŒ˜K command palette
â”‚   â”‚   â”œâ”€â”€ RemoteChat.tsx             # Chat overlay with 3D toggle
â”‚   â”‚   â””â”€â”€ SheepRun.tsx               # Game component (archived)
â”‚   â”œâ”€â”€ public/                # Assets (icons, logos)
â”‚   â”œâ”€â”€ package.json           # npm dependencies
â”‚   â””â”€â”€ tailwind.config.ts     # Tailwind configuration
â”‚
â”œâ”€â”€ install.sh                 # One-command setup script
â”œâ”€â”€ .claude/launch.json        # Dev server configurations
â””â”€â”€ README.md                  # This file
```

---

## ğŸ”§ Configuration

### Backend Setup (`.env`)

Create `/backend/.env`:

```bash
# Optional: Override default Ollama endpoint
OLLAMA_BASE_URL=http://localhost:11434

# Optional: ElevenLabs for text-to-speech
ELEVENLABS_API_KEY=your_key_here

# Optional: Twilio for voice calls
TWILIO_ACCOUNT_SID=your_sid_here
TWILIO_AUTH_TOKEN=your_token_here
TWILIO_PHONE_NUMBER=+1234567890
```

### Frontend Setup (Environment Variables)

```bash
NEXT_PUBLIC_API_BASE_URL=http://localhost:8000
```

---

## ğŸŒ API Endpoints

### Chat & Sessions
```
POST   /v1/chat              # Send message to AI
GET    /v1/sessions          # List all sessions
GET    /v1/sessions/{id}     # Get session details
DELETE /v1/sessions/{id}     # Archive session
POST   /v1/sessions/{id}/export  # Export session
```

### Models & Memory
```
GET    /v1/models            # List available Ollama models
GET    /v1/memory            # Get cross-session memory
POST   /v1/memory            # Add to memory
DELETE /v1/memory/{id}       # Remove from memory
```

### Prompts & System
```
GET    /v1/prompts           # List all prompt templates
POST   /v1/prompts           # Create prompt
PUT    /v1/prompts/{id}      # Update prompt
DELETE /v1/prompts/{id}      # Delete prompt
GET    /v1/dashboard/stats   # Dashboard statistics
```

### Voice (Optional)
```
POST   /v1/voice/record      # Record voice input
POST   /v1/voice/transcribe  # Transcribe audio
GET    /v1/voice/models      # List available TTS voices
```

---

## ğŸ® Interactive Features

### Landing Page
- **3D Animated Grid** - Fully rotatable with mouse drag
- **Auto-rotating** - Smooth background animation
- **Animated boxes** - Floating 3D objects moving on grid
- **One-click launch** - "Launch App" button to enter dashboard

### Dashboard (`/app`)
- **âŒ˜K Command Palette** - Type to search 50+ actions
- **Stats at a glance** - Sessions, messages, recordings, prompts
- **Quick actions** - Fast access to main features
- **Action search** - Category-based action discovery
- **Subtle 3D background** - Blurred grid for visual interest

### Chat Overlay
- **Minimizable chat** - Glassmorphic floating panel
- **Voice input/output** - Speech recognition + TTS
- **Model selector** - Choose between available Ollama models
- **3D grid toggle** (âœ¨ button) - Full-screen interactive 3D while chatting
- **Auto-resizing input** - Smart textarea that grows with content

---

## ğŸš€ Running Locally

### Start Everything
```bash
./install.sh
```

### Or Start Manually

**Terminal 1 - Backend:**
```bash
cd backend
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
python main.py
# Runs on http://localhost:8000
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
# Runs on http://localhost:3002
```

**Terminal 3 - Ollama (if not auto-started):**
```bash
ollama serve
# Listens on http://localhost:11434
```

---

## ğŸ“Š Prompt Types

### 1. **TASK** - Action-oriented
```
Execute specific tasks with clear outcomes
Example: "Write a blog post about AI"
```

### 2. **LEARN** - Knowledge acquisition
```
Explain concepts and deep dive
Example: "Teach me about quantum computing"
```

### 3. **ROLES** - Role-based responses
```
Adopt persona for specialized output
Example: "As a Python expert, review my code"
```

### 4. **SCHEDULE** - Time-based planning
```
Create schedules and timelines
Example: "Plan a 2-week project schedule"
```

### 5. **TIME_TARGET** - Deadline-driven
```
Work backward from deadline
Example: "I have 1 hour to prepare presentation"
```

### 6. **DEBATE** - Multi-perspective analysis
```
Argue multiple sides of an issue
Example: "Pros and cons of remote work"
```

### 7. **INTERVIEW** - Q&A format
```
Interview-style conversation
Example: "Interview me for a job"
```

### 8. **FORBIDDEN_WORDS** - Constrained output
```
Avoid certain words/phrases
Example: "Explain AI without using the word 'intelligent'"
```

### 9. **READ** - Document analysis
```
Analyze and extract from documents
Example: "Summarize this research paper"
```

---

## ğŸ’¾ Data Storage

### `/backend/data/` Directory

```
data/
â”œâ”€â”€ sessions/
â”‚   â”œâ”€â”€ session_UUID_1.json      # Individual session file
â”‚   â”œâ”€â”€ session_UUID_2.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ recordings/
â”‚   â”œâ”€â”€ recording_UUID_1.wav     # Voice recordings
â”‚   â””â”€â”€ ...
â””â”€â”€ memory.jsonl                 # Cross-session memory (line-delimited JSON)
```

### Session File Format
```json
{
  "id": "session-123",
  "created_at": "2025-02-22T10:00:00Z",
  "messages": [
    {
      "id": "msg-1",
      "role": "user",
      "content": "Hello",
      "timestamp": "2025-02-22T10:00:00Z"
    },
    {
      "id": "msg-2",
      "role": "assistant",
      "content": "Hi! How can I help?",
      "timestamp": "2025-02-22T10:00:05Z"
    }
  ],
  "metadata": {
    "model": "llama3.2",
    "prompt_type": "TASK"
  }
}
```

---

## ğŸ” Privacy & Security

âœ… **Zero telemetry** - No data ever leaves your machine
âœ… **No account required** - Run completely offline
âœ… **Local LLM** - Via Ollama (not using OpenAI/proprietary APIs)
âœ… **File-based storage** - You own all your data
âœ… **Full autonomy** - Complete control over system behavior

**Important:** Keep your `/backend/data/` directory private - it contains all your conversations and memories.

---

## ğŸ› ï¸ Troubleshooting

### Port Already in Use
```bash
# Find and kill process using port 8000 or 3002
lsof -ti:8000 | xargs kill -9
lsof -ti:3002 | xargs kill -9
```

### Ollama Model Issues
```bash
# List available models
ollama list

# Pull a specific model
ollama pull llama3.2

# Check Ollama status
curl http://localhost:11434/api/tags
```

### Build Cache Corruption
```bash
cd frontend
rm -rf .next node_modules
npm install
npm run build
```

### Backend Errors
```bash
cd backend
source venv/bin/activate
pip install -r requirements.txt --upgrade
python main.py
```

---

## ğŸ“ˆ Performance Tips

1. **Choose appropriate model size** - Larger models (70B+) require more VRAM
2. **Limit chat history** - Memory system automatically compresses to last 24 messages
3. **Disable auto-rotate 3D grid** - On low-spec machines, simplify the scene
4. **Use local Ollama** - Always run Ollama on same machine for best performance
5. **Archive old sessions** - Reduces memory footprint of active sessions

---

## ğŸ¯ Roadmap

- [ ] Multi-turn reasoning with extended context
- [ ] Custom fine-tuning of local models
- [ ] Plugin system for custom tools
- [ ] Real-time collaboration (local network)
- [ ] Advanced memory indexing and retrieval
- [ ] GUI model management
- [ ] Batch processing capabilities
- [ ] Analytics dashboard

---

## ğŸ’¬ Support

For issues or questions:
1. Check `/backend/main.py` comments for endpoint details
2. Review `/backend/prompt_system.py` for prompt configuration
3. Check browser console for frontend errors
4. Review server logs: `tail -f /backend/data/activity.log`

---

## ğŸ“„ License

**LocalAgent v1.0** - Open source, fully yours to run locally.

No cloud. No tracking. No limits.

**Your AI. Your machine. Your rules.** ğŸ”

---

## ğŸš€ One-Time Payment Model

LocalAgent is distributed as a **one-time payment** with QR code access. Once installed, it's yours forever:

- No subscriptions
- No SaaS costs
- No recurring fees
- Full source code access
- Run as many instances as you want

**Coming soon to a machine near you!**

